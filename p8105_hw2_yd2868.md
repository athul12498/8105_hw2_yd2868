p8105_hw2_yd2868
================
2025-09-30

Load needed packs and data.

``` r
library(readxl)
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

# problem1

import needed data

``` r
pols_df = 
  read.csv("./fivethirtyeight_datasets/pols-month.csv")|>
  janitor::clean_names()

unemploy_df =
  read.csv("./fivethirtyeight_datasets/unemployment.csv")|>
  janitor::clean_names()

snp_df = 
  read.csv("./fivethirtyeight_datasets/snp.csv")|>
  janitor::clean_names()
```

process data

``` r
pols_clean_df = 
  pols_df|>
  separate(mon, into = c("year","month","day"), sep ="-")|>
  mutate (month = recode(month,
    `01` = "January",
    `02` = "February",
    `03` = "March",
    `04` = "April",
    `05` = "May",
    `06` = "June",
    `07` = "July",
    `08` = "August",
    `09` = "September",
    `10` = "October",
    `11` = "November",
    `12` = "December" ),
    president = case_when(
    prez_gop == 1 ~ "gop",
    prez_dem == 1 ~ "dem"
   ))|>
   select(-c("day","prez_gop","prez_dem"))

snp_clean_df =
  snp_df|>
  separate(date, into = c("month","day","year"), sep ="/")|>
  select(c("year","month","close"))|>
  mutate (month = recode(month,
    `1` = "January",
    `2` = "February",
    `3` = "March",
    `4` = "April",
    `5` = "May",
    `6` = "June",
    `7` = "July",
    `8` = "August",
    `9` = "September",
    `10` = "October",
    `11` = "November",
    `12` = "December" ),
    year = as.numeric(year),
    year = ifelse(year < 50, year + 2000, year + 1900),
    year = as.character(year)
    )

unemploy_clean_df =
  unemploy_df|>
  pivot_longer(jan:dec, 
             names_to = "month", 
             values_to = "unemploy"
             )|>
  mutate(month = recode(month,
    "jan" = "January",
    "feb" = "February",
    "mar" = "March",
    "apr" = "April",
    "may" = "May",
    "jun" = "June",
    "jul" = "July",
    "aug" = "August",
    "sep" = "September",
    "oct" = "October",
    "nov" = "November",
    "dec" = "December"),
    year = as.character(year)
    )
```

join datas

``` r
join_df = 
  left_join(pols_clean_df, snp_clean_df, by = c("year", "month") )|>
  left_join(unemploy_clean_df, by = c("year", "month"))
```

The pols dataset contains monthly political data, the snp dataset
provides monthly S&P 500 closing values, and the unemployment dataset
records monthly unemployment rates. All three datasets include year and
month variables, which allow them to be merged into a single dataset
that combines political, economic, and employment information for each
month and year.

# problem2

import and clean data

``` r
MR_trashW_df = 
  read_excel("./202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N709",
             na = c(".","NA",""))|>
  janitor::clean_names()|>
  select(-c(homes_powered))|>
  mutate(
    sports_balls = as.integer(round(sports_balls))
  )

Pro_trashW_df = 
  read_excel("./202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M134",
             na = c(".","NA",""))|>
  janitor::clean_names()|>
  select(-c(homes_powered))
  

Gwy_trashW_df = 
  read_excel("./202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynns Falls Trash Wheel",
             range = "A2:L351",
             na = c(".","NA",""))|>
  janitor::clean_names()|>
  select(-c(homes_powered))
```

join all three dataset

``` r
Gwy_trashW_df = mutate(Gwy_trashW_df,Wheel = "Gwynns",
       year = as.double(year))
Pro_trashW_df = mutate(Pro_trashW_df,Wheel = "Professor",
       year = as.double(year))
MR_trashW_df = mutate(MR_trashW_df,Wheel = "MR",
       year = as.double(year))
trashW_df = bind_rows(MR_trashW_df,Pro_trashW_df,Gwy_trashW_df)
```

There is a total of 1188 observations for these three wheels. It
contains weight, volume for each dumpster, and the number of certain
kinds of trash such as plastic bottles, polystyrene, cigarette butts,
glass bottles, plastic bags, wrappers, sports balls. For example, the
total weight of trash collected by Professor Trash Wheel is 282.26 tons,
and the total number of cigarette butts collected by Gwynnda in June of
2022 is 18120.

# problem3

import data

``` r
ZipCodes_df = 
  read.csv("./zillow_data/Zip Codes.csv")|>
  janitor::clean_names()

Zip_df = 
  read.csv("./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")|>
  janitor::clean_names()|>
  arrange(by = region_name)
```

change variable names to join data

``` r
Zip_clean_df = 
  Zip_df|>
  rename( 
    zip_code = region_name,
    county = county_name
          )|>
  mutate(county = str_remove(county, " County$"))|>
  select(-region_type)
  

Zip_join_df = 
  inner_join(Zip_clean_df , ZipCodes_df,by = c("zip_code","county"))
```

extract strange data

``` r
Zip_s = Zip_clean_df[Zip_clean_df$zip_code == "11693",]
ZipCodes_s = ZipCodes_df[ZipCodes_df$zip_code == "11693",]
```

clean joined data

``` r
Zip_join_clean_df = 
  Zip_join_df|>
  select(1:2 , 4:7 , county , neighborhood, zip_code , 125:129 , everything())|>
  pivot_longer(
    cols = starts_with("x20"),
    names_to = "date", 
    values_to = "rent_value"
  ) |>
  select(-state_name)
```

compare rental prices in January 2021 to prices in January 2020

``` r
Zip_21J = filter(Zip_join_clean_df, str_starts(date, "x2021_01"))
Zip_20J = filter(Zip_join_clean_df, str_starts(date, "x2020_01"))
Zip_drop = 
  inner_join(Zip_20J, Zip_21J, by = "zip_code")|>
  mutate(drop = rent_value.x - rent_value.y)|>
  select(drop, zip_code, county.x, neighborhood.x)|>
  arrange(desc(drop))

Zip_drop_10 =
  Zip_drop|>
  slice(1:10) |>
  rename(
    neighborhood = neighborhood.x,
    county = county.x
  )
```

This tidy data includes variables about the identification of the house
(region_id and size rank), location of the house (state, city, metro,
county, neighborhood), ID of the location (zip code, state fips, county
code, county fips, and file date for these IDs), and rent value on a
certain date. There are a total of 17168 observations, among them 6719
values are NA, maybe due to lack of samples or data lost. There are 148
unique zip code and 43 unique neighborhoods in this dataset.

There is also one observation has zip code 11693 and county Queens. But
for zip code 11693, there is only one record of county Kings . This
observation is not included in the dataset.

The zip codes that appear in the zip code dataset but not in the Zillow
Rental Price dataset are here.

    ##   [1] 10464 10474 10475 10499 10550 10704 10705 10803 11202 11224 11239 11241
    ##  [13] 11242 11243 11245 11247 11251 11252 11256 10008 10020 10041 10043 10045
    ##  [25] 10047 10048 10055 10072 10080 10081 10082 10087 10101 10102 10103 10104
    ##  [37] 10105 10106 10107 10108 10109 10110 10111 10112 10113 10114 10115 10116
    ##  [49] 10117 10118 10119 10120 10121 10122 10123 10124 10125 10126 10129 10130
    ##  [61] 10131 10132 10133 10138 10149 10150 10151 10152 10153 10154 10155 10156
    ##  [73] 10157 10158 10159 10160 10161 10163 10164 10165 10166 10167 10168 10169
    ##  [85] 10170 10171 10172 10173 10174 10175 10176 10177 10178 10179 10185 10197
    ##  [97] 10199 10213 10242 10249 10256 10259 10260 10261 10265 10268 10269 10270
    ## [109] 10271 10272 10273 10274 10275 10276 10277 10278 10279 10281 10285 10286
    ## [121] 10292 11001 11004 11005 11040 11096 11351 11352 11359 11362 11363 11371
    ## [133] 11380 11381 11386 11405 11411 11412 11413 11414 11416 11417 11419 11420
    ## [145] 11421 11422 11423 11424 11425 11427 11428 11429 11430 11431 11433 11436
    ## [157] 11439 11451 11499 11559 11580 11690 11694 11695 11697 10302 10307 10309
    ## [169] 10310 10311 10313

These regions might be industrial or commercial regions, and they almost
don’t have houses for rent.

10 ZIP codes with largest drop are listed here.

    ## # A tibble: 10 × 4
    ##     drop zip_code county   neighborhood                 
    ##    <dbl>    <int> <chr>    <chr>                        
    ##  1  913.    10007 New York Lower Manhattan              
    ##  2  748.    10069 New York <NA>                         
    ##  3  714.    10009 New York Lower East Side              
    ##  4  712.    10016 New York Gramercy Park and Murray Hill
    ##  5  710.    10001 New York Chelsea and Clinton          
    ##  6  710.    10002 New York Lower East Side              
    ##  7  706.    10004 New York Lower Manhattan              
    ##  8  698.    10038 New York Lower Manhattan              
    ##  9  686.    10012 New York Greenwich Village and Soho   
    ## 10  685.    10010 New York Gramercy Park and Murray Hill

After comparison, the data tells that 75 out of 82 observations whose
rent values are not NA have shown a drop in price. The Pandemic has
influenced the price significantly.
